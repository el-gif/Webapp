{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Build feature and output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T08:36:55.708991Z",
     "iopub.status.busy": "2025-01-20T08:36:55.708666Z",
     "iopub.status.idle": "2025-01-20T08:37:14.542156Z",
     "shell.execute_reply": "2025-01-20T08:37:14.541651Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'WPPs+production+wind.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m all_commissioning_dates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m all_production_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWPPs+production+wind.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     14\u001b[0m     WPP_production_wind \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# collect data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\webapp_env_conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'WPPs+production+wind.json'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# lists for all data\n",
    "all_turbine_types = []\n",
    "all_hub_heights = []\n",
    "all_capacities = []\n",
    "all_commissioning_dates = []\n",
    "all_production_data = []\n",
    "\n",
    "with open(f\"../data/WPPs+production+wind.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    WPP_production_wind = json.load(file)\n",
    "\n",
    "# collect data\n",
    "for wpp in WPP_production_wind:\n",
    "    all_turbine_types.append([wpp[\"Turbine\"] if pd.notna(wpp[\"Turbine\"]) else \"nan\" for wpp in WPP_production_wind])\n",
    "    all_hub_heights.append(wpp[\"Hub_height\"] if not pd.isna(wpp[\"Hub_height\"]) else 100)\n",
    "    all_capacities.append(wpp[\"Capacity\"])\n",
    "    all_commissioning_dates.append(\"2015/06\" if wpp[\"Commission_date\"] == \"nan\" else f\"{wpp['Commission_date']}/06\" if isinstance(wpp[\"Commission_date\"], str) and \"/\" not in wpp[\"Commission_date\"] else wpp[\"Commission_date\"])\n",
    "    all_production_data.append(wpp[\"Production\"])\n",
    "\n",
    "# One-Hot-Encoding for turbine types\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "turbine_types_onehot = encoder.fit_transform(np.array(all_turbine_types).reshape(-1, 1))\n",
    "\n",
    "# convert to datetime\n",
    "standardised_dates = pd.to_datetime(all_commissioning_dates, format='%Y/%m')\n",
    "\n",
    "# calculate age\n",
    "current_date = pd.Timestamp(\"2024-12-01\")\n",
    "ages = current_date.year * 12 + current_date.month - (standardised_dates.year * 12 + standardised_dates.month)\n",
    "\n",
    "# create combined features and output lists\n",
    "combined_features_raw = []\n",
    "output_raw = []\n",
    "\n",
    "# convert data in feature arrays\n",
    "for idx, production_data in enumerate(all_production_data):\n",
    "    num_rows = len(production_data)\n",
    "\n",
    "    # repetitions for common features\n",
    "    turbine_type_repeated = np.tile(turbine_types_onehot[idx], (num_rows, 1))\n",
    "    hub_height_repeated = np.full((num_rows, 1), all_hub_heights[idx])\n",
    "    age_repeated = np.full((num_rows, 1), ages[idx])\n",
    "\n",
    "    # extract production values and wind speeds\n",
    "    production_values = np.array([entry[1] for entry in production_data]).reshape(-1, 1) / all_capacities[idx]\n",
    "    wind_speeds = np.array([entry[2] for entry in production_data]).reshape(-1, 1)\n",
    "\n",
    "    # combine all features\n",
    "    combined_chunk = np.hstack((\n",
    "        turbine_type_repeated,\n",
    "        hub_height_repeated,\n",
    "        age_repeated,\n",
    "        wind_speeds\n",
    "    ))\n",
    "\n",
    "    # add the data\n",
    "    combined_features_raw.append(combined_chunk)\n",
    "    output_raw.append(production_values)\n",
    "\n",
    "np.save(\"turbine_types_order.npy\", encoder.categories_[0])\n",
    "\n",
    "# combine all data chunks to one array\n",
    "combined_features_raw = np.vstack(combined_features_raw)\n",
    "output_raw = np.vstack(output_raw)\n",
    "\n",
    "# round all values to two decimal places\n",
    "combined_features_raw = np.round(combined_features_raw, decimals=4)\n",
    "output_raw = np.round(output_raw, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = current_date.year * 12 + current_date.month - (standardised_dates.year * 12 + standardised_dates.month)\n",
    "\n",
    "# create combined features and output lists\n",
    "combined_features_raw = []\n",
    "output_raw = []\n",
    "\n",
    "# convert data in feature arrays\n",
    "for idx, production_data in enumerate(all_production_data):\n",
    "    num_rows = len(production_data)\n",
    "\n",
    "    # repetitions for common features\n",
    "    turbine_type_repeated = np.tile(turbine_types_onehot[idx], (num_rows, 1))\n",
    "    hub_height_repeated = np.full((num_rows, 1), all_hub_heights[idx])\n",
    "    age_repeated = np.full((num_rows, 1), ages[idx])\n",
    "\n",
    "    # extract production values and wind speeds\n",
    "    production_values = np.array([entry[1] for entry in production_data]).reshape(-1, 1) / all_capacities[idx]\n",
    "    wind_speeds = np.array([entry[2] for entry in production_data]).reshape(-1, 1)\n",
    "\n",
    "    # combine all features\n",
    "    combined_chunk = np.hstack((\n",
    "        turbine_type_repeated,\n",
    "        hub_height_repeated,\n",
    "        age_repeated,\n",
    "        wind_speeds\n",
    "    ))\n",
    "\n",
    "    # add the data\n",
    "    combined_features_raw.append(combined_chunk)\n",
    "    output_raw.append(production_values)\n",
    "\n",
    "np.save(\"turbine_types_order.npy\", encoder.categories_[0])\n",
    "\n",
    "# combine all data chunks to one array\n",
    "combined_features_raw = np.vstack(combined_features_raw)\n",
    "output_raw = np.vstack(output_raw)\n",
    "\n",
    "# round all values to two decimal places\n",
    "combined_features_raw = np.round(combined_features_raw, decimals=4)\n",
    "output_raw = np.round(output_raw, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_capacities = []\n",
    "all_commissioning_dates = []\n",
    "all_production_data = []\n",
    "\n",
    "with open(f\"WPPs+production+wind.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    WPP_production_wind = json.load(file)\n",
    "\n",
    "# collect data\n",
    "for wpp in WPP_production_wind:\n",
    "    all_turbine_types.append([wpp[\"Turbine\"] if pd.notna(wpp[\"Turbine\"]) else \"nan\" for wpp in WPP_production_wind])\n",
    "    all_hub_heights.append(wpp[\"Hub_height\"] if not pd.isna(wpp[\"Hub_height\"]) else 100)\n",
    "    all_capacities.append(wpp[\"Capacity\"])\n",
    "    all_commissioning_dates.append(\"2015/06\" if wpp[\"Commission_date\"] == \"nan\" else f\"{wpp['Commission_date']}/06\" if isinstance(wpp[\"Commission_date\"], str) and \"/\" not in wpp[\"Commission_date\"] else wpp[\"Commission_date\"])\n",
    "    all_production_data.append(wpp[\"Production\"])\n",
    "\n",
    "# One-Hot-Encoding for turbine types\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "turbine_types_onehot = encoder.fit_transform(np.array(all_turbine_types).reshape(-1, 1))\n",
    "\n",
    "# convert to datetime\n",
    "standardised_dates = pd.to_datetime(all_commissioning_dates, format='%Y/%m')\n",
    "\n",
    "# calculate age\n",
    "current_date = pd.Timestamp(\"2024-12-01\")\n",
    "ages = current_date.year * 12 + current_date.month - (standardised_dates.year * 12 + standardised_dates.month)\n",
    "\n",
    "# create combined features and output lists\n",
    "combined_features_raw = []\n",
    "output_raw = []\n",
    "\n",
    "# convert data in feature arrays\n",
    "for idx, production_data in enumerate(all_production_data):\n",
    "    num_rows = len(production_data)\n",
    "\n",
    "    # repetitions for common features\n",
    "    turbine_type_repeated = np.tile(turbine_types_onehot[idx], (num_rows, 1))\n",
    "    hub_height_repeated = np.full((num_rows, 1), all_hub_heights[idx])\n",
    "    age_repeated = np.full((num_rows, 1), ages[idx])\n",
    "\n",
    "    # extract production values and wind speeds\n",
    "    production_values = np.array([entry[1] for entry in production_data]).reshape(-1, 1) / all_capacities[idx]\n",
    "    wind_speeds = np.array([entry[2] for entry in production_data]).reshape(-1, 1)\n",
    "\n",
    "    # combine all features\n",
    "    combined_chunk = np.hstack((\n",
    "        turbine_type_repeated,\n",
    "        hub_height_repeated,\n",
    "        age_repeated,\n",
    "        wind_speeds\n",
    "    ))\n",
    "\n",
    "    # add the data\n",
    "    combined_features_raw.append(combined_chunk)\n",
    "    output_raw.append(production_values)\n",
    "\n",
    "np.save(\"turbine_types_order.npy\", encoder.categories_[0])\n",
    "\n",
    "# combine all data chunks to one array\n",
    "combined_features_raw = np.vstack(combined_features_raw)\n",
    "output_raw = np.vstack(output_raw)\n",
    "\n",
    "# round all values to two decimal places\n",
    "combined_features_raw = np.round(combined_features_raw, decimals=4)\n",
    "output_raw = np.round(output_raw, decimals=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scale feature vector and define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T08:37:14.544188Z",
     "iopub.status.busy": "2025-01-20T08:37:14.543917Z",
     "iopub.status.idle": "2025-01-20T08:37:29.048170Z",
     "shell.execute_reply": "2025-01-20T08:37:29.047706Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "combined_features = combined_features_raw.copy()\n",
    "output = output_raw.copy()\n",
    "\n",
    "# Separate Scaler für jedes Feature\n",
    "scaler_wind = StandardScaler()\n",
    "scaler_ages = StandardScaler()\n",
    "scaler_hub_heights = StandardScaler()\n",
    "\n",
    "# Skalieren der einzelnen Features\n",
    "combined_features[:, -1] = scaler_wind.fit_transform(combined_features[:, -1].reshape(-1, 1)).flatten() # scale wind speeds\n",
    "combined_features[:, -2] = scaler_ages.fit_transform(combined_features[:, -2].reshape(-1, 1)).flatten()  # scale ages\n",
    "combined_features[:, -3] = scaler_hub_heights.fit_transform(combined_features[:, -3].reshape(-1, 1)).flatten()  # scale hub heights\n",
    "\n",
    "# Speichere alle Scaler in einem Dictionary\n",
    "scalers = {\n",
    "    \"winds\": scaler_wind,\n",
    "    \"ages\": scaler_ages,\n",
    "    \"hub_heights\": scaler_hub_heights,\n",
    "}\n",
    "\n",
    "# Speichere das Dictionary mit Joblib\n",
    "joblib.dump(scalers, \"scalers.pkl\")\n",
    "\n",
    "# Dataset-Klasse für PyTorch\n",
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.targets[index]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Erstellung der PyTorch-Datasets\n",
    "dataset = WindPowerDataset(combined_features, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T08:37:29.050177Z",
     "iopub.status.busy": "2025-01-20T08:37:29.049851Z",
     "iopub.status.idle": "2025-01-20T08:37:29.054752Z",
     "shell.execute_reply": "2025-01-20T08:37:29.054386Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, use_dropout=False, dropout_rate=0.3, \n",
    "                 use_batch_norm=False, activation_fn=nn.ReLU):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Erste Schicht\n",
    "        layers.append(nn.Linear(input_size, 256))\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(256))\n",
    "        layers.append(activation_fn())\n",
    "\n",
    "        # Zweite Schicht\n",
    "        layers.append(nn.Linear(256, 128))\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(128))\n",
    "        layers.append(activation_fn())\n",
    "\n",
    "        # Dritte Schicht\n",
    "        layers.append(nn.Linear(128, 64))\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(64))\n",
    "        layers.append(activation_fn())\n",
    "\n",
    "        # Dropout nach der letzten versteckten Schicht (optional)\n",
    "        if use_dropout:\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        # Ausgabeschicht\n",
    "        layers.append(nn.Linear(64, 1))\n",
    "\n",
    "        # Modell zusammenstellen\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Hyperparameter search: Training, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T08:37:29.056455Z",
     "iopub.status.busy": "2025-01-20T08:37:29.056290Z",
     "iopub.status.idle": "2025-01-21T10:29:13.227858Z",
     "shell.execute_reply": "2025-01-21T10:29:13.227448Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/abp224/home/miniforge3/envs/new_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 08:37:30,940] A new study created in memory with name: no-name-e3da9bd4-da9c-4182-b2b8-ce6e81df00b5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "Device: cuda\n",
      "\n",
      "CUDA Details:\n",
      "CUDA Version: 12.4\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "  - Compute Capability: (8, 9)\n",
      "  - Memory Allocated: 0.00 MB\n",
      "  - Memory Cached: 0.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: batch_size=32, lr=0.00085, number_epochs=28, use_dropout=True, dropout_rate=0.48942446890278213, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/15 [1:16:25<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:   0%|          | 0/15 [1:16:25<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:   7%|▋         | 1/15 [1:16:25<17:50:03, 4585.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 09:53:56,890] Trial 0 finished with value: 1142.3736184263203 and parameters: {'batch_size': 29, 'lr': 0.0008548450444075019, 'number_epochs': 28, 'use_dropout': True, 'dropout_rate': 0.48942446890278213, 'use_batch_norm': False}. Best is trial 0 with value: 1142.3736184263203.\n",
      "Evaluating: batch_size=32, lr=0.00756, number_epochs=86, use_dropout=False, dropout_rate=0.4213625934337293, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:   7%|▋         | 1/15 [5:01:03<17:50:03, 4585.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:   7%|▋         | 1/15 [5:01:03<17:50:03, 4585.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:  13%|█▎        | 2/15 [5:01:03<35:26:50, 9816.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 13:38:34,250] Trial 1 finished with value: 2920.6556711634134 and parameters: {'batch_size': 38, 'lr': 0.007556862216392946, 'number_epochs': 86, 'use_dropout': False, 'dropout_rate': 0.4213625934337293, 'use_batch_norm': False}. Best is trial 0 with value: 1142.3736184263203.\n",
      "Evaluating: batch_size=128, lr=0.00577, number_epochs=23, use_dropout=True, dropout_rate=0.42179034787013836, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 0. Best value: 1142.37:  13%|█▎        | 2/15 [5:31:45<35:26:50, 9816.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  13%|█▎        | 2/15 [5:31:45<35:26:50, 9816.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  20%|██        | 3/15 [5:31:45<20:35:01, 6175.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 14:09:16,569] Trial 2 finished with value: 593.6471844751527 and parameters: {'batch_size': 106, 'lr': 0.00577064775868788, 'number_epochs': 23, 'use_dropout': True, 'dropout_rate': 0.42179034787013836, 'use_batch_norm': True}. Best is trial 2 with value: 593.6471844751527.\n",
      "Evaluating: batch_size=128, lr=0.00040, number_epochs=34, use_dropout=False, dropout_rate=0.4944972715492967, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  20%|██        | 3/15 [6:16:38<20:35:01, 6175.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  20%|██        | 3/15 [6:16:38<20:35:01, 6175.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  27%|██▋       | 4/15 [6:16:38<14:40:03, 4800.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 14:54:09,296] Trial 3 finished with value: 763.72887179906 and parameters: {'batch_size': 105, 'lr': 0.0003972356125203253, 'number_epochs': 34, 'use_dropout': False, 'dropout_rate': 0.4944972715492967, 'use_batch_norm': True}. Best is trial 2 with value: 593.6471844751527.\n",
      "Evaluating: batch_size=32, lr=0.00071, number_epochs=49, use_dropout=False, dropout_rate=0.20706398619215927, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  27%|██▋       | 4/15 [9:11:44<14:40:03, 4800.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  27%|██▋       | 4/15 [9:11:44<14:40:03, 4800.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  33%|███▎      | 5/15 [9:11:44<19:02:57, 6857.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 17:49:14,956] Trial 4 finished with value: 2326.3154161535754 and parameters: {'batch_size': 27, 'lr': 0.0007053258766825379, 'number_epochs': 49, 'use_dropout': False, 'dropout_rate': 0.20706398619215927, 'use_batch_norm': True}. Best is trial 2 with value: 593.6471844751527.\n",
      "Evaluating: batch_size=64, lr=0.00274, number_epochs=93, use_dropout=True, dropout_rate=0.15950495314842994, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  33%|███▎      | 5/15 [12:26:26<19:02:57, 6857.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  33%|███▎      | 5/15 [12:26:26<19:02:57, 6857.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  40%|████      | 6/15 [12:26:26<21:14:42, 8498.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 21:03:57,066] Trial 5 finished with value: 2561.6055117504543 and parameters: {'batch_size': 72, 'lr': 0.002743322065354356, 'number_epochs': 93, 'use_dropout': True, 'dropout_rate': 0.15950495314842994, 'use_batch_norm': True}. Best is trial 2 with value: 593.6471844751527.\n",
      "Evaluating: batch_size=32, lr=0.00029, number_epochs=86, use_dropout=True, dropout_rate=0.4350601739601343, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  40%|████      | 6/15 [17:32:06<21:14:42, 8498.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  40%|████      | 6/15 [17:32:06<21:14:42, 8498.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  47%|████▋     | 7/15 [17:32:06<26:02:06, 11715.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 02:09:37,703] Trial 6 finished with value: 3893.311306730006 and parameters: {'batch_size': 28, 'lr': 0.0002941467444519105, 'number_epochs': 86, 'use_dropout': True, 'dropout_rate': 0.4350601739601343, 'use_batch_norm': True}. Best is trial 2 with value: 593.6471844751527.\n",
      "Evaluating: batch_size=128, lr=0.00196, number_epochs=23, use_dropout=True, dropout_rate=0.35965811417582827, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 2. Best value: 593.647:  47%|████▋     | 7/15 [17:58:39<26:02:06, 11715.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  47%|████▋     | 7/15 [17:58:39<26:02:06, 11715.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  53%|█████▎    | 8/15 [17:58:39<16:30:51, 8493.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 02:36:10,462] Trial 7 finished with value: 543.7350735859195 and parameters: {'batch_size': 125, 'lr': 0.0019607963759473005, 'number_epochs': 23, 'use_dropout': True, 'dropout_rate': 0.35965811417582827, 'use_batch_norm': False}. Best is trial 7 with value: 543.7350735859195.\n",
      "Evaluating: batch_size=64, lr=0.00897, number_epochs=20, use_dropout=True, dropout_rate=0.13824455122900364, use_batch_norm=True\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  53%|█████▎    | 8/15 [18:41:20<16:30:51, 8493.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  53%|█████▎    | 8/15 [18:41:20<16:30:51, 8493.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  60%|██████    | 9/15 [18:41:20<11:03:52, 6638.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 03:18:51,554] Trial 8 finished with value: 737.402132051712 and parameters: {'batch_size': 72, 'lr': 0.008974438766333337, 'number_epochs': 20, 'use_dropout': True, 'dropout_rate': 0.13824455122900364, 'use_batch_norm': True}. Best is trial 7 with value: 543.7350735859195.\n",
      "Evaluating: batch_size=32, lr=0.00049, number_epochs=92, use_dropout=False, dropout_rate=0.10286230959353695, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  60%|██████    | 9/15 [22:49:52<11:03:52, 6638.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  60%|██████    | 9/15 [22:49:52<11:03:52, 6638.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  67%|██████▋   | 10/15 [22:49:52<12:46:03, 9192.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 07:27:23,010] Trial 9 finished with value: 3207.4745196163044 and parameters: {'batch_size': 26, 'lr': 0.0004943711772695012, 'number_epochs': 92, 'use_dropout': False, 'dropout_rate': 0.10286230959353695, 'use_batch_norm': False}. Best is trial 7 with value: 543.7350735859195.\n",
      "Evaluating: batch_size=128, lr=0.00201, number_epochs=64, use_dropout=True, dropout_rate=0.3114225339122173, use_batch_norm=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  67%|██████▋   | 10/15 [24:02:12<12:46:03, 9192.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  67%|██████▋   | 10/15 [24:02:12<12:46:03, 9192.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  73%|███████▎  | 11/15 [24:02:12<8:33:50, 7707.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 08:39:43,567] Trial 10 finished with value: 1093.2626359054977 and parameters: {'batch_size': 127, 'lr': 0.002007209111422981, 'number_epochs': 64, 'use_dropout': True, 'dropout_rate': 0.3114225339122173, 'use_batch_norm': False}. Best is trial 7 with value: 543.7350735859195.\n",
      "Evaluating: batch_size=128, lr=0.00010, number_epochs=10, use_dropout=True, dropout_rate=0.33659592356347234, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 7. Best value: 543.735:  73%|███████▎  | 11/15 [24:14:02<8:33:50, 7707.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  73%|███████▎  | 11/15 [24:14:02<8:33:50, 7707.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  80%|████████  | 12/15 [24:14:02<4:38:56, 5578.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 08:51:33,771] Trial 11 finished with value: 367.2218166891764 and parameters: {'batch_size': 110, 'lr': 0.00010155300193027382, 'number_epochs': 10, 'use_dropout': True, 'dropout_rate': 0.33659592356347234, 'use_batch_norm': False}. Best is trial 11 with value: 367.2218166891764.\n",
      "Evaluating: batch_size=128, lr=0.00011, number_epochs=11, use_dropout=True, dropout_rate=0.30925826932178585, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  80%|████████  | 12/15 [24:27:02<4:38:56, 5578.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  80%|████████  | 12/15 [24:27:02<4:38:56, 5578.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  87%|████████▋ | 13/15 [24:27:02<2:17:30, 4125.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 09:04:33,338] Trial 12 finished with value: 381.09450653062675 and parameters: {'batch_size': 128, 'lr': 0.00011307233154504967, 'number_epochs': 11, 'use_dropout': True, 'dropout_rate': 0.30925826932178585, 'use_batch_norm': False}. Best is trial 11 with value: 367.2218166891764.\n",
      "Evaluating: batch_size=128, lr=0.00011, number_epochs=11, use_dropout=True, dropout_rate=0.2573436629428657, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  87%|████████▋ | 13/15 [24:40:03<2:17:30, 4125.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  87%|████████▋ | 13/15 [24:40:03<2:17:30, 4125.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  93%|█████████▎| 14/15 [24:40:03<51:55, 3115.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 09:17:34,495] Trial 13 finished with value: 381.41230562817725 and parameters: {'batch_size': 100, 'lr': 0.00010569099227507707, 'number_epochs': 11, 'use_dropout': True, 'dropout_rate': 0.2573436629428657, 'use_batch_norm': False}. Best is trial 11 with value: 367.2218166891764.\n",
      "Evaluating: batch_size=64, lr=0.00011, number_epochs=42, use_dropout=True, dropout_rate=0.32615381201539556, use_batch_norm=False\n",
      "  Fold 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  93%|█████████▎| 14/15 [25:51:42<51:55, 3115.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222:  93%|█████████▎| 14/15 [25:51:42<51:55, 3115.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222: 100%|██████████| 15/15 [25:51:42<00:00, 3471.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Best trial: 11. Best value: 367.222: 100%|██████████| 15/15 [25:51:42<00:00, 6206.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 10:29:13,220] Trial 14 finished with value: 1084.925905217107 and parameters: {'batch_size': 89, 'lr': 0.00010843041840445346, 'number_epochs': 42, 'use_dropout': True, 'dropout_rate': 0.32615381201539556, 'use_batch_norm': False}. Best is trial 11 with value: 367.2218166891764.\n",
      "\n",
      "Beste Parameterkombination:\n",
      "{'batch_size': 110, 'lr': 0.00010155300193027382, 'number_epochs': 10, 'use_dropout': True, 'dropout_rate': 0.33659592356347234, 'use_batch_norm': False}\n",
      "Bester Validierungsverlust: 0.015207221777925835\n",
      "FrozenTrial(number=0, state=TrialState.COMPLETE, values=[1142.3736184263203], datetime_start=datetime.datetime(2025, 1, 20, 8, 37, 30, 941914), datetime_complete=datetime.datetime(2025, 1, 20, 9, 53, 56, 890564), params={'batch_size': 29, 'lr': 0.0008548450444075019, 'number_epochs': 28, 'use_dropout': True, 'dropout_rate': 0.48942446890278213, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 32, 'resource_usage': 1125.875, 'elapsed_time': 4585.947127580643, 'avg_val_loss': 0.015321516985955446, 'weighted_score': 1142.3736184263203}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=0, value=None)\n",
      "FrozenTrial(number=1, state=TrialState.COMPLETE, values=[2920.6556711634134], datetime_start=datetime.datetime(2025, 1, 20, 9, 53, 56, 893261), datetime_complete=datetime.datetime(2025, 1, 20, 13, 38, 34, 250446), params={'batch_size': 38, 'lr': 0.007556862216392946, 'number_epochs': 86, 'use_dropout': False, 'dropout_rate': 0.4213625934337293, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 32, 'resource_usage': 1125.875, 'elapsed_time': 13477.356069803238, 'avg_val_loss': 0.015762004609539117, 'weighted_score': 2920.6556711634134}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=1, value=None)\n",
      "FrozenTrial(number=2, state=TrialState.COMPLETE, values=[593.6471844751527], datetime_start=datetime.datetime(2025, 1, 20, 13, 38, 34, 253020), datetime_complete=datetime.datetime(2025, 1, 20, 14, 9, 16, 569181), params={'batch_size': 106, 'lr': 0.00577064775868788, 'number_epochs': 23, 'use_dropout': True, 'dropout_rate': 0.42179034787013836, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 1842.3149600028992, 'avg_val_loss': 0.01532079095480085, 'weighted_score': 593.6471844751527}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=2, value=None)\n",
      "FrozenTrial(number=3, state=TrialState.COMPLETE, values=[763.72887179906], datetime_start=datetime.datetime(2025, 1, 20, 14, 9, 16, 571718), datetime_complete=datetime.datetime(2025, 1, 20, 14, 54, 9, 296531), params={'batch_size': 105, 'lr': 0.0003972356125203253, 'number_epochs': 34, 'use_dropout': False, 'dropout_rate': 0.4944972715492967, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 2692.723801612854, 'avg_val_loss': 0.015185794148652532, 'weighted_score': 763.72887179906}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=3, value=None)\n",
      "FrozenTrial(number=4, state=TrialState.COMPLETE, values=[2326.3154161535754], datetime_start=datetime.datetime(2025, 1, 20, 14, 54, 9, 299463), datetime_complete=datetime.datetime(2025, 1, 20, 17, 49, 14, 955932), params={'batch_size': 27, 'lr': 0.0007053258766825379, 'number_epochs': 49, 'use_dropout': False, 'dropout_rate': 0.20706398619215927, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 32, 'resource_usage': 1125.875, 'elapsed_time': 10505.655468463898, 'avg_val_loss': 0.015537434658927977, 'weighted_score': 2326.3154161535754}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=4, value=None)\n",
      "FrozenTrial(number=5, state=TrialState.COMPLETE, values=[2561.6055117504543], datetime_start=datetime.datetime(2025, 1, 20, 17, 49, 14, 958948), datetime_complete=datetime.datetime(2025, 1, 20, 21, 3, 57, 65742), params={'batch_size': 72, 'lr': 0.002743322065354356, 'number_epochs': 93, 'use_dropout': True, 'dropout_rate': 0.15950495314842994, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 64, 'resource_usage': 1125.875, 'elapsed_time': 11682.10577249527, 'avg_val_loss': 0.015595419000370179, 'weighted_score': 2561.6055117504543}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=5, value=None)\n",
      "FrozenTrial(number=6, state=TrialState.COMPLETE, values=[3893.311306730006], datetime_start=datetime.datetime(2025, 1, 20, 21, 3, 57, 68415), datetime_complete=datetime.datetime(2025, 1, 21, 2, 9, 37, 703646), params={'batch_size': 28, 'lr': 0.0002941467444519105, 'number_epochs': 86, 'use_dropout': True, 'dropout_rate': 0.4350601739601343, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 32, 'resource_usage': 1125.875, 'elapsed_time': 18340.634217977524, 'avg_val_loss': 0.015771890834777536, 'weighted_score': 3893.311306730006}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=6, value=None)\n",
      "FrozenTrial(number=7, state=TrialState.COMPLETE, values=[543.7350735859195], datetime_start=datetime.datetime(2025, 1, 21, 2, 9, 37, 706534), datetime_complete=datetime.datetime(2025, 1, 21, 2, 36, 10, 462032), params={'batch_size': 125, 'lr': 0.0019607963759473005, 'number_epochs': 23, 'use_dropout': True, 'dropout_rate': 0.35965811417582827, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 1592.7545402050018, 'avg_val_loss': 0.015275908198543502, 'weighted_score': 543.7350735859195}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=7, value=None)\n",
      "FrozenTrial(number=8, state=TrialState.COMPLETE, values=[737.402132051712], datetime_start=datetime.datetime(2025, 1, 21, 2, 36, 10, 464656), datetime_complete=datetime.datetime(2025, 1, 21, 3, 18, 51, 554547), params={'batch_size': 72, 'lr': 0.008974438766333337, 'number_epochs': 20, 'use_dropout': True, 'dropout_rate': 0.13824455122900364, 'use_batch_norm': True}, user_attrs={'transformed_batch_size': 64, 'resource_usage': 1125.875, 'elapsed_time': 2561.088894844055, 'avg_val_loss': 0.015588471501531694, 'weighted_score': 737.402132051712}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=8, value=None)\n",
      "FrozenTrial(number=9, state=TrialState.COMPLETE, values=[3207.4745196163044], datetime_start=datetime.datetime(2025, 1, 21, 3, 18, 51, 557434), datetime_complete=datetime.datetime(2025, 1, 21, 7, 27, 23, 10626), params={'batch_size': 26, 'lr': 0.0004943711772695012, 'number_epochs': 92, 'use_dropout': False, 'dropout_rate': 0.10286230959353695, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 32, 'resource_usage': 1125.875, 'elapsed_time': 14911.452110767365, 'avg_val_loss': 0.015162438051815262, 'weighted_score': 3207.4745196163044}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=9, value=None)\n",
      "FrozenTrial(number=10, state=TrialState.COMPLETE, values=[1093.2626359054977], datetime_start=datetime.datetime(2025, 1, 21, 7, 27, 23, 13249), datetime_complete=datetime.datetime(2025, 1, 21, 8, 39, 43, 566806), params={'batch_size': 127, 'lr': 0.002007209111422981, 'number_epochs': 64, 'use_dropout': True, 'dropout_rate': 0.3114225339122173, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 4340.392418861389, 'avg_val_loss': 0.015253555366296846, 'weighted_score': 1093.2626359054977}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=10, value=None)\n",
      "FrozenTrial(number=11, state=TrialState.COMPLETE, values=[367.2218166891764], datetime_start=datetime.datetime(2025, 1, 21, 8, 39, 43, 569473), datetime_complete=datetime.datetime(2025, 1, 21, 8, 51, 33, 770880), params={'batch_size': 110, 'lr': 0.00010155300193027382, 'number_epochs': 10, 'use_dropout': True, 'dropout_rate': 0.33659592356347234, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 710.1884617805481, 'avg_val_loss': 0.015207221777925835, 'weighted_score': 367.2218166891764}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=11, value=None)\n",
      "FrozenTrial(number=12, state=TrialState.COMPLETE, values=[381.09450653062675], datetime_start=datetime.datetime(2025, 1, 21, 8, 51, 33, 773823), datetime_complete=datetime.datetime(2025, 1, 21, 9, 4, 33, 338711), params={'batch_size': 128, 'lr': 0.00011307233154504967, 'number_epochs': 11, 'use_dropout': True, 'dropout_rate': 0.30925826932178585, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 779.5518794059753, 'avg_val_loss': 0.015217749052807383, 'weighted_score': 381.09450653062675}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=12, value=None)\n",
      "FrozenTrial(number=13, state=TrialState.COMPLETE, values=[381.41230562817725], datetime_start=datetime.datetime(2025, 1, 21, 9, 4, 33, 341335), datetime_complete=datetime.datetime(2025, 1, 21, 9, 17, 34, 495552), params={'batch_size': 100, 'lr': 0.00010569099227507707, 'number_epochs': 11, 'use_dropout': True, 'dropout_rate': 0.2573436629428657, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 128, 'resource_usage': 1125.875, 'elapsed_time': 781.1408686637878, 'avg_val_loss': 0.015219825699383255, 'weighted_score': 381.41230562817725}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=13, value=None)\n",
      "FrozenTrial(number=14, state=TrialState.COMPLETE, values=[1084.925905217107], datetime_start=datetime.datetime(2025, 1, 21, 9, 17, 34, 498287), datetime_complete=datetime.datetime(2025, 1, 21, 10, 29, 13, 220715), params={'batch_size': 89, 'lr': 0.00010843041840445346, 'number_epochs': 42, 'use_dropout': True, 'dropout_rate': 0.32615381201539556, 'use_batch_norm': False}, user_attrs={'transformed_batch_size': 64, 'resource_usage': 1125.875, 'elapsed_time': 4298.7090055942535, 'avg_val_loss': 0.015173497093590435, 'weighted_score': 1084.925905217107}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=128, log=False, low=16, step=1), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'number_epochs': IntDistribution(high=100, log=False, low=10, step=1), 'use_dropout': CategoricalDistribution(choices=(True, False)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'use_batch_norm': CategoricalDistribution(choices=(True, False))}, trial_id=14, value=None)\n",
      "GPU wurde erfolgreich während des Trainings verwendet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "import time\n",
    "import pynvml\n",
    "import psutil\n",
    "\n",
    "# Ressourcenüberwachung initialisieren\n",
    "gpu_used = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    pynvml.nvmlInit()\n",
    "    gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # GPU 0 verwenden\n",
    "\n",
    "n_splits = 2  # Anzahl der Folds für Kreuzvalidierung\n",
    "\n",
    "def system_info():\n",
    "    print(\"PyTorch Version:\", torch.__version__)\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nCUDA Details:\")\n",
    "        print(\"CUDA Version:\", torch.version.cuda)\n",
    "        print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"  - Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "            print(f\"  - Memory Allocated: {torch.cuda.memory_allocated(i) / 1024**2:.2f} MB\")\n",
    "            print(f\"  - Memory Cached: {torch.cuda.memory_reserved(i) / 1024**2:.2f} MB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    system_info()\n",
    "\n",
    "# Bewertungsfunktion\n",
    "def objective(trial):\n",
    "    original_batch_size = trial.suggest_int(\"batch_size\", 16, 128)\n",
    "    batch_size = int(2 ** round(np.log2(original_batch_size)))  # Transformierte Batch-Größe\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    number_epochs = trial.suggest_int(\"number_epochs\", 10, 100)\n",
    "    use_dropout = trial.suggest_categorical(\"use_dropout\", [True, False])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    use_batch_norm = trial.suggest_categorical(\"use_batch_norm\", [True, False])\n",
    "\n",
    "    # Speichern der transformierten Batch-Größe als Attribut\n",
    "    trial.set_user_attr(\"transformed_batch_size\", batch_size)\n",
    "\n",
    "    print(f\"Evaluating: batch_size={batch_size}, lr={lr:.5f}, number_epochs={number_epochs}, \"\n",
    "          f\"use_dropout={use_dropout}, dropout_rate={dropout_rate}, use_batch_norm={use_batch_norm}\")\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    len_dataset = len(dataset)\n",
    "\n",
    "    input_size = combined_features.shape[1]\n",
    "    avg_val_loss = 0.0  # Durchschnittlicher Validierungsverlust\n",
    "    start_time = time.time()  # Zeitmessung starten\n",
    "    max_memory_usage = 0  # Maximale Speicher-Auslastung\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len_dataset)), 1):\n",
    "        print(f\"  Fold {fold}/{kf.n_splits}\")\n",
    "\n",
    "        # use static instead of dynamic computational graphs\n",
    "        model = torch.jit.script(MLP(input_size=input_size, use_dropout=use_dropout, dropout_rate=dropout_rate, use_batch_norm=use_batch_norm)).to(device)\n",
    "\n",
    "        train_fold_dataset = Subset(dataset, train_idx)\n",
    "        val_fold_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_fold_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_fold_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        criterion = nn.HuberLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(number_epochs):\n",
    "            model.train()\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    memory_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "                    max_memory_usage = max(max_memory_usage, memory_info.used / 1024 ** 2)  # MB\n",
    "                    global gpu_used\n",
    "                    gpu_used = True\n",
    "                else:\n",
    "                    max_memory_usage = max(max_memory_usage, psutil.virtual_memory().used / 1024 ** 2)  # MB\n",
    "\n",
    "        model.eval() # deactivates Batch normalisation and Dropout\n",
    "        fold_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                val_outputs = model(batch_x)\n",
    "                fold_val_loss += criterion(val_outputs, batch_y).item()\n",
    "                \n",
    "        avg_val_loss += fold_val_loss / len(val_loader)\n",
    "\n",
    "    avg_val_loss /= kf.n_splits\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    weighted_score = 0.6 * avg_val_loss + 0.2 * elapsed_time + 0.2 * max_memory_usage\n",
    "\n",
    "    trial.set_user_attr(\"resource_usage\", max_memory_usage)\n",
    "    trial.set_user_attr(\"elapsed_time\", elapsed_time)\n",
    "    trial.set_user_attr(\"avg_val_loss\", avg_val_loss)\n",
    "    trial.set_user_attr(\"weighted_score\", weighted_score)\n",
    "\n",
    "    return weighted_score\n",
    "\n",
    "# Optuna-Optimierung starten\n",
    "best_val_loss = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=15, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBeste Parameterkombination:\")\n",
    "print(study.best_params)\n",
    "\n",
    "with open(\"best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f)\n",
    "\n",
    "# Ausgabe des besten Validierungsverlusts\n",
    "best_trial = study.best_trial\n",
    "print(f\"Bester Validierungsverlust: {best_trial.user_attrs['avg_val_loss']}\")\n",
    "\n",
    "for trial in study.trials:\n",
    "    print(trial)\n",
    "\n",
    "# Debugging: Überprüfung, ob GPU verwendet wurde\n",
    "if gpu_used:\n",
    "    print(\"GPU wurde erfolgreich während des Trainings verwendet.\")\n",
    "else:\n",
    "    print(\"GPU wurde nicht verwendet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webapp_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
