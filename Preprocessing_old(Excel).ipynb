{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of historical production data: discard data of unwanted power plants, retain monthly files - old version, because too many nan values or missing rows detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearbeite Datei: E:\\MA_data\\raw production history ENTSO-E\\2015_02_ActualGenerationOutputPerGenerationUnit_16.1.A_r2.1.csv\n",
      "Excel-Datei wurde erfolgreich erstellt: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_new\\production_summary_2015_02.xlsx\n",
      "Bearbeite Datei: E:\\MA_data\\raw production history ENTSO-E\\2015_03_ActualGenerationOutputPerGenerationUnit_16.1.A_r2.1.csv\n",
      "Excel-Datei wurde erfolgreich erstellt: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_new\\production_summary_2015_03.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Basisverzeichnisse\n",
    "input_dir = r\"E:\\MA_data\\raw production history ENTSO-E\"\n",
    "output_dir = r\"C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_old\"\n",
    "\n",
    "# Funktion zum Auffüllen fehlender Stunden und Zählen der fehlenden Werte\n",
    "def fill_missing_hours(data, start_time, end_time):\n",
    "    # Erstelle eine vollständige Zeitreihe für den Monat\n",
    "    full_time_range = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "\n",
    "    # Umwandeln der 'DateTime (UTC)'-Spalte in datetime-Objekte\n",
    "    data.loc[:, 'DateTime (UTC)'] = pd.to_datetime(data['DateTime (UTC)'])\n",
    "\n",
    "    # Setze den Index auf die DateTime-Spalte\n",
    "    data.set_index('DateTime (UTC)', inplace=True)\n",
    "    \n",
    "    # Reindexiere die Daten, um fehlende Stunden mit NaN aufzufüllen\n",
    "    data = data.reindex(full_time_range)\n",
    "\n",
    "    # Zähle die Anzahl der fehlenden Werte\n",
    "    missing_count = data['ActualGenerationOutput(MW)'].isna().sum()\n",
    "    \n",
    "    # Fülle fehlende Werte mit 0 (sowohl gerade hinzugefügte Zeilen mit nan Werten, als auch bereits bestehende Zeilen, in denen schon vorher keine Werte für die Produktion waren)\n",
    "    data['ActualGenerationOutput(MW)'] = data['ActualGenerationOutput(MW)'].fillna(0)\n",
    "    \n",
    "    # Setze den Index zurück\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    return data, missing_count\n",
    "\n",
    "number_missing_values = []\n",
    "\n",
    "# Liste der Monate von 2015-01 bis 2024-10 generieren\n",
    "months = pd.date_range(start=\"2015-01\", end=\"2015-02\", freq=\"MS\").strftime(\"%Y_%m\").tolist()\n",
    "\n",
    "# For-Schleife für jede Datei\n",
    "for i, month in enumerate(months):\n",
    "\n",
    "    # Dateipfad erstellen\n",
    "    input_file = os.path.join(input_dir, f\"{month}_ActualGenerationOutputPerGenerationUnit_16.1.A_r2.1.csv\")\n",
    "    output_file = os.path.join(output_dir, f\"production_summary_{month}.xlsx\")\n",
    "\n",
    "    # Datei einlesen\n",
    "    print(f\"Bearbeite Datei: {input_file}\")\n",
    "    data = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "    # Filtere nach GenerationUnitType == 'Wind Onshore' oder 'Wind Offshore'\n",
    "    filtered_data = data[(data['GenerationUnitType'] == 'Wind Onshore ') | (data['GenerationUnitType'] == 'Wind Offshore ')]\n",
    "\n",
    "    # Wichtige Spalten identifizieren, 'AreaCode', 'AreaDisplayName', 'AreaTypeCode' and 'MapCode' of identical WPPs may differ --> use at least one of them as a criterion to identify unique windfarms, and sort out the duplicates manually, because otherwise, the production data are appended twice to the same wind farm\n",
    "    unique_windfarms = filtered_data[['GenerationUnitName', 'GenerationUnitCode', 'GenerationUnitType', 'GenerationUnitInstalledCapacity(MW)', 'AreaCode']].drop_duplicates()\n",
    "    \n",
    "    # Auffüllen fehlender Stunden und Zählen der fehlenden Werte\n",
    "    start_time = data['DateTime (UTC)'].min()\n",
    "    end_time = data['DateTime (UTC)'].max()\n",
    "\n",
    "    number_missing_values.append([])\n",
    "\n",
    "    # Listen für die Produktion zu jeder Stunde hinzufügen\n",
    "    production_data = []\n",
    "    for _, row in unique_windfarms.iterrows():\n",
    "        windfarm_data = filtered_data[(filtered_data['GenerationUnitName'] == row['GenerationUnitName']) & (filtered_data['AreaCode'] == row['AreaCode'])]\n",
    "        windfarm_data, missing_count = fill_missing_hours(windfarm_data, start_time, end_time)\n",
    "        production_values = windfarm_data['ActualGenerationOutput(MW)'].tolist() # where production is nan, the WPP has consumed and not generator power\n",
    "        row_data = {\n",
    "            'GenerationUnitName': row['GenerationUnitName'],\n",
    "            'GenerationUnitCode': row['GenerationUnitCode'],\n",
    "            'GenerationUnitType': row['GenerationUnitType'],\n",
    "            'GenerationUnitInstalledCapacity(MW)': row['GenerationUnitInstalledCapacity(MW)'],\n",
    "            'Production (MW)': production_values\n",
    "        }\n",
    "        production_data.append(row_data)\n",
    "\n",
    "        # Zähle die fehlenden Werte für diesen Monat\n",
    "        number_missing_values[i].append(missing_count)\n",
    "\n",
    "    # DataFrame erstellen und in Excel speichern\n",
    "    output_df = pd.DataFrame(production_data)\n",
    "    output_df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(\"Anzahl der fehlenden Werte je Windkraftwerk für diesen Monat:\", number_missing_values[i])\n",
    "    print(f\"Excel-Datei wurde erfolgreich erstellt: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the number_missing_values as excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mache die Liste flach, um alle Elemente in einer einzigen Liste zu sammeln\n",
    "number_missing_values_flat = [item for sublist in number_missing_values for item in sublist]\n",
    "\n",
    "# Berechne den Durchschnitt\n",
    "average = sum(number_missing_values_flat) / len(number_missing_values_flat)\n",
    "print(f\"Der Durchschnitt ist: {average}\")\n",
    "\n",
    "# Überschrift\n",
    "column_name = \"number of missing elements per wind power plant for all investigated months\"\n",
    "\n",
    "# DataFrame erstellen\n",
    "df = pd.DataFrame({column_name: [str(sublist) for sublist in number_missing_values]})\n",
    "\n",
    "# Datei speichern\n",
    "output_file = r\"data\\number_missing_values.xlsx\"  # Pfad und Dateiname anpassen\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Die Excel-Datei wurde erfolgreich gespeichert: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge all monthly production data files to one combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeite Datei: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_new\\production_summary_2015_01.xlsx\n",
      "Verarbeite Datei: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_new\\production_summary_2015_02.xlsx\n",
      "Verarbeite Datei: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed_new\\production_summary_2015_03.xlsx\n",
      "Zusammengeführte Excel-Tabelle wurde gespeichert unter: C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\production_summary_all.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Verzeichnisse\n",
    "input_dir = r\"C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed\"\n",
    "output_file = r\"C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\production_summary_all.xlsx\"\n",
    "\n",
    "# Liste der Monate von 2015_01 bis 2024_10\n",
    "months = pd.date_range(start=\"2015-01\", end=\"2024-10\", freq=\"MS\").strftime(\"%Y_%m\").tolist()\n",
    "\n",
    "columns_old = ['GenerationUnitName', 'GenerationUnitCode', 'GenerationUnitType', 'GenerationUnitInstalledCapacity(MW)', 'AreaDisplayName', 'MapCode', 'AreaTypeCode']\n",
    "# Leeres DataFrame für das Endergebnis\n",
    "columns = columns_old + months\n",
    "final_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Einlesen der einzelnen Dateien\n",
    "for month in months:\n",
    "    input_file = os.path.join(input_dir, f\"production_summary_{month}.xlsx\")\n",
    "\n",
    "    # Überprüfen, ob die Datei existiert\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Datei nicht gefunden: {input_file}\")\n",
    "        continue\n",
    "\n",
    "    # Datei einlesen\n",
    "    print(f\"Verarbeite Datei: {input_file}\")\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Sicherstellen, dass die Spalte 'Production (MW)' existiert\n",
    "    if 'Production (MW)' not in df.columns:\n",
    "        print(f\"Spalte 'Production (MW)' fehlt in {input_file}\")\n",
    "        continue\n",
    "\n",
    "    df.rename(columns={'Production (MW)': month}, inplace=True)\n",
    "\n",
    "    # Zusammenführen der Daten\n",
    "    if final_df.empty:\n",
    "        final_df = df\n",
    "    else:\n",
    "        # Zusammenführen: Gleiche Windkraftanlagen zusammenführen, neue hinzufügen\n",
    "        final_df = pd.merge(final_df, df, how='outer', on=columns_old)\n",
    "\n",
    "# Excel-Tabelle speichern\n",
    "final_df.to_excel(output_file, index=False)\n",
    "print(f\"Zusammengeführte Excel-Tabelle wurde erfolgreich gespeichert unter: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise filling rate of production data file (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datei laden\n",
    "file_path = r\"C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed\\production_summary_all.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Anzahl der Windkraftanlagen pro AreaDisplayName\n",
    "counts = df['AreaDisplayName'].value_counts()\n",
    "\n",
    "# Berechnung der prozentualen Ausfüllquote pro AreaDisplayName\n",
    "percentages = {}\n",
    "for area in counts.index:\n",
    "    subset = df[df['AreaDisplayName'] == area]\n",
    "    total_cells = len(subset) * (len(subset.columns) - 6)  # Exkludiere nicht-produktive Spalten\n",
    "    filled_cells = subset.iloc[:, 6:].notna().sum().sum()  # Nur Produktionsdaten berücksichtigen\n",
    "    percentages[area] = (filled_cells / total_cells) * 100\n",
    "\n",
    "# Balkendiagramm erstellen\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(counts.index, counts.values, color='skyblue')\n",
    "ax.set_title('Anzahl der Windkraftanlagen mit Produktionsdaten pro Land')\n",
    "ax.set_xlabel('Land (AreaDisplayName)')\n",
    "ax.set_ylabel('Anzahl der Windkraftanlagen')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Prozentsätze als Text hinzufügen\n",
    "for bar, area in zip(bars, counts.index):\n",
    "    height = bar.get_height()\n",
    "    percentage = percentages[area]\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{percentage:.1f} %', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise filling rate of production data file (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datei laden\n",
    "file_path = r\"C:\\Users\\alexa\\Documents\\Webapp\\data\\production_history\\processed\\production_summary_all.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Liste der Monatskolumnen\n",
    "month_columns = [col for col in df.columns if col.startswith(\"20\")]\n",
    "\n",
    "# Anzahl der Windkraftanlagen pro AreaDisplayName (Land)\n",
    "windfarm_count = df.groupby(\"AreaDisplayName\").size()\n",
    "\n",
    "# Durchschnittliche Ausfüllquote pro Land\n",
    "fill_rates = df[month_columns].notna().mean(axis=1)  # Berechne pro Windkraftanlage\n",
    "average_fill_rate_per_country = df.groupby(\"AreaDisplayName\")[month_columns].apply(\n",
    "    lambda x: x.notna().mean(axis=1).mean()\n",
    ")\n",
    "\n",
    "# Plot erstellen\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Linke y-Achse: Anzahl der Windkraftanlagen\n",
    "ax1.bar(\n",
    "    windfarm_count.index,\n",
    "    windfarm_count.values,\n",
    "    label=\"Anzahl der Windkraftanlagen\",\n",
    "    alpha=0.7\n",
    ")\n",
    "ax1.set_ylabel(\"Anzahl der Windkraftanlagen\", fontsize=12)\n",
    "ax1.set_xlabel(\"AreaDisplayName (Land)\", fontsize=12)\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# Rechte y-Achse: Durchschnittliche Ausfüllquote\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(\n",
    "    average_fill_rate_per_country.index,\n",
    "    average_fill_rate_per_country.values * 100,  # Prozentualer Wert\n",
    "    label=\"Durchschnittliche Ausfüllquote (%)\",\n",
    "    alpha=0.5,\n",
    "    color=\"orange\"\n",
    ")\n",
    "ax2.set_ylabel(\"Durchschnittliche Ausfüllquote (%)\", fontsize=12)\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "# Titel und Layout\n",
    "plt.title(\"Windkraftanlagen und Ausfüllquote pro Land\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Steps with assigning a meaningful name to UK WPPs just as in current Preprocessing file. Then perform manual assignment to The Wind Power database.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign ENTSO-E WPPs to The Wind Power WPPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "df_wind_power = pd.read_excel(\"data/WPPs+production.xlsx\")\n",
    "df_assignment = pd.read_excel(\"data/Assignment_old.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtere nur Zeilen, bei denen \"ID_The-Wind-Power\" nicht \"not found\" ist\n",
    "df_assignment = df_assignment[df_assignment[\"ID_The-Wind-Power\"] != \"not found\"]\n",
    "\n",
    "# Extrahiere und entpacke alle gültigen IDs aus der Spalte \"ID_The-Wind-Power\"\n",
    "def extract_ids(value):\n",
    "    # Überprüfen, ob der Wert eine Liste ist, und ggf. in einzelne IDs zerlegen\n",
    "    if isinstance(value, str) and value.startswith(\"[\") and value.endswith(\"]\"):\n",
    "        return eval(value)  # Konvertiert die Zeichenkette in eine Liste\n",
    "    elif isinstance(value, (int, str)):\n",
    "        return [int(value)]  # Einzelne IDs werden in eine Liste gewandelt\n",
    "    return []\n",
    "\n",
    "valid_ids = set()\n",
    "df_assignment[\"ID_The-Wind-Power\"].apply(lambda x: valid_ids.update(extract_ids(x)))\n",
    "\n",
    "df_filtered = df_wind_power[df_wind_power['ID'].isin(valid_ids)].copy()\n",
    "actual_ids = set(df_filtered['ID'])\n",
    "suspended_ids = valid_ids - actual_ids\n",
    "\n",
    "print(\"number potential WPPs:\", len(valid_ids))\n",
    "print(\"number actual WPPs:\", len(actual_ids))\n",
    "print(\"number suspended WPPs (no name, location, capacity or status not in operation):\", len(suspended_ids))\n",
    "\n",
    "# Füge Spalten für Produktion von 2015_01 bis 2024_10 hinzu\n",
    "new_columns = {f\"{year}_{month:02d}\": [[] for _ in range(len(df_filtered))]\n",
    "            for year in range(2015, 2025) for month in range(1, 13)\n",
    "            if f\"{year}_{month:02d}\" in df_assignment.columns}\n",
    "\n",
    "# Füge die neuen Spalten zum DataFrame hinzu\n",
    "df_filtered = pd.concat([df_filtered, pd.DataFrame(new_columns, index=df_filtered.index)], axis=1)\n",
    "\n",
    "# Gehe durch jede Zeile der Assignment-Datei und füge Produktionsdaten hinzu\n",
    "for _, row in df_assignment.iterrows():\n",
    "    \n",
    "    ids_in_row = extract_ids(row[\"ID_The-Wind-Power\"])\n",
    "    first_id = ids_in_row[0]\n",
    "\n",
    "    if first_id in suspended_ids:\n",
    "        continue # jump to next iteration, because following line would fail for suspended_ids\n",
    "\n",
    "    current_index = df_filtered.loc[df_filtered['ID'] == first_id].index[0]\n",
    "\n",
    "    # add production values for each month, only requires the first ID\n",
    "    for year in range(2015, 2025):\n",
    "        for month in range(1, 13):\n",
    "            column_name = f\"{year}_{month:02d}\"\n",
    "            if column_name in df_assignment.columns: # neglect 2024_11 and 2024_12\n",
    "                production_month = row[column_name]\n",
    "                if isinstance(production_month, str): # type(value) = str, meaning value = production values\n",
    "                    production_month = production_month.replace(\"nan\", \"0\") # where production is nan, the WPP has consumed and not generator power\n",
    "                    production_month = eval(production_month) # [[]] <-- \"[[]]\"\n",
    "                    production_month = production_month[0] # [] <-- [[]]\n",
    "                    existing_production = df_filtered.at[current_index, column_name]\n",
    "                    \n",
    "                    if existing_production == []: # no production values in cell for this month\n",
    "                        df_filtered.at[current_index, column_name] = production_month\n",
    "                    else: # several production values to be added to one WPP\n",
    "                        combined_production = [a + b for a, b in zip(existing_production, production_month)]\n",
    "                        df_filtered.at[current_index, column_name] = combined_production\n",
    "\n",
    "    # add capacities of WPPs, if several are assigned to one row in the assignment table\n",
    "    if first_id in actual_ids and len(ids_in_row) > 1: # only treat every id once here, because rows are discarded\n",
    "        total_power = 0\n",
    "        for id in ids_in_row:\n",
    "            total_power += df_filtered.loc[df_filtered['ID'] == id, \"Total power\"].item() # add power\n",
    "            if id != first_id:\n",
    "                df_filtered = df_filtered[df_filtered['ID'] != id] # delete from dataframe\n",
    "        df_filtered.loc[df_filtered['ID'] == first_id, \"Total power\"] = total_power\n",
    "    \n",
    "    # keep track of treated IDs to not try to delete rows twice \n",
    "    for id in ids_in_row:\n",
    "        if id in actual_ids:\n",
    "            actual_ids.discard(id)\n",
    "\n",
    "actual_cluster_ids = set(df_filtered['ID'])\n",
    "print(\"number WPPs after clustering\", len(actual_cluster_ids))\n",
    "df_filtered.to_excel(\"data/WPPs+production.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webapp_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
